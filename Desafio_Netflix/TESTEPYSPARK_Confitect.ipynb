{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_cZeB0nyZwZA81oXW4NfFGLlnHVvK208",
      "authorship_tag": "ABX9TyPRWjsAHQEg/2pp4f6aeWin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denise-Pro/Case_DataEngineer_Confitec/blob/main/Desafio_Netflix/TESTEPYSPARK_Confitect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando a Biblioteca, cujas funções permitirão se conectar e manipular dados de Buckets do AWS S3"
      ],
      "metadata": {
        "id": "Hzs_SaX4XCZo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-reH9PCSrXIm",
        "outputId": "ae88aa9f-774c-44cb-b0ba-8bf2abe029da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.8/dist-packages (1.26.42)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from boto3) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.42 in /usr/local/lib/python3.8/dist-packages (from boto3) (1.29.42)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.42->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.42->boto3) (1.26.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.42->boto3) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando as funções / bibliotecas necessárias para conexão, upload, tratamento de erros e  manipulação de arquivos, tanto no S3 como no file system local"
      ],
      "metadata": {
        "id": "ZFD9XRowXzrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "from datetime import datetime\n",
        "import botocore\n",
        "from botocore.exceptions import ProfileNotFound, ClientError\n",
        "# from botocore.exceptions import ClientError\n",
        "import os"
      ],
      "metadata": {
        "id": "MMBlHs7irhgL"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conectando ao S3 e extraindo o arquivo parquet que servirá como fonte de dados para o processo"
      ],
      "metadata": {
        "id": "lqCujne03lMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta próxima célula eu instancio as variáveis de conexão com um Bucket do s3 chamado 'detch-bucket01', cuja criação se deu através do portal da AWS. \n",
        "Também crio uma pasta no file system local para armazenar o arquivo parquet, que também foi baixado e salvo no Bucket 'detch-bucket01' manualmente"
      ],
      "metadata": {
        "id": "NfJp7TtL4Cvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Buket = 'detch-bucket01'\n",
        "File = \"OriginaisNetflix20221230.parquet\"\n",
        "path = \"load_data_Netflix/OriginaisNetflix20221230.parquet\"\n",
        "ACCESS_ID = 'AKIA6D667OAARISPB2OJ'\n",
        "ACCESS_KEY =  'nTFYpTubQdmgkUsqWnwxBZSCUz4VqSEX5ySynXMK'\n",
        "s3 = boto3.resource('s3',\n",
        "      aws_access_key_id=ACCESS_ID,\n",
        "      aws_secret_access_key= ACCESS_KEY)\n",
        "\n",
        "today = datetime.today()\n",
        "dt_string = today.strftime(\"%Y%m%d\")\n",
        "print(\"date =\", dt_string)\n",
        "\n",
        "File_extract = dt_string + \"OriginaisNetflix.parquet\"\n",
        "\n",
        "folder_extract = 'sourceNetflix'\n",
        "\n",
        "path_source = Buket + '/' + folder_extract + '/' + File_extract\n",
        "\n",
        "if not os.path.exists(Buket):\n",
        "    os.mkdir(Buket)\n",
        "    os.mkdir(folder_extract)\n",
        "\n",
        "# if not os.path.exists(folder_extract):\n",
        "#     os.mkdir(folder_extract)\n",
        "  \n",
        "print(path_source) "
      ],
      "metadata": {
        "id": "FTP61YaTcE8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d73b4f61-19e2-422a-8a1c-b29b197b3d3c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date = 20230104\n",
            "detch-bucket01/sourceNetflix/20230104OriginaisNetflix.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conectando ao Buket S3 e fazendo download do arquivo de origem dos dados"
      ],
      "metadata": {
        "id": "sGWJp8Aj6IS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  s3.Bucket(Buket).download_file(path, path_source)\n",
        "  print(\"successful extraction!\")\n",
        "  \n",
        "except botocore.exceptions.ClientError as e:\n",
        "  if e.response['Error']['Code'] == \"404\":\n",
        "    print(\"file not found.\")\n",
        "  else:\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlyHIfFqsc6w",
        "outputId": "86070263-c188-4160-d8ac-008c5e975a33"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successful extraction!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando a biblioteca spark cujas funções permitirão processar e manipular um grande volume de dados"
      ],
      "metadata": {
        "id": "bEGKRG8_6Wrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld0lBfPndW4f",
        "outputId": "eef85137-c1d2-487a-bbd9-fa58ff627558"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark==3.3.1 in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark==3.3.1) (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando os pacotes e funções do spark que serão úteis "
      ],
      "metadata": {
        "id": "3NV7ZQjT7ICV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import DateType, TimestampType\n",
        "from datetime import timedelta\n",
        "from dateutil import parser"
      ],
      "metadata": {
        "id": "5MtARbkbzrWG"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instanciando o Spark e salvando em um Dataframe o conteúdo dos dados de origem"
      ],
      "metadata": {
        "id": "Du4JrOo67dCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName(\"PySpark Read Netflix Parquet\").getOrCreate()\n",
        "df_Netflix = spark.read.parquet(path_source)\n",
        "df_Netflix.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlkYVZlL0ZJ2",
        "outputId": "cf79104e-eaa5-4c21-e40c-5d5ea404e8c7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+---------+--------------------+-------------+--------------+-----------+---------+---------+----------+------+-----+--------+--------------------+\n",
            "|               Title|               Genre|         GenreLabels| Premiere|             Seasons|SeasonsParsed|EpisodesParsed|     Length|MinLength|MaxLength|    Status|Active|Table|Language|         dt_inclusao|\n",
            "+--------------------+--------------------+--------------------+---------+--------------------+-------------+--------------+-----------+---------+---------+----------+------+-----+--------+--------------------+\n",
            "|      House of Cards|     Political drama|     political,drama| 1-Feb-13|6 seasons, 73 epi...|            6|            73| 42–59 min.|       42|       59|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|       Hemlock Grove|     Horror/thriller|     horror,thriller|19-Apr-13|3 seasons, 33 epi...|            3|            33| 45–58 min.|       45|       58|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|Orange Is the New...|        Comedy-drama|        comedy-drama|11-Jul-13|6 seasons, 78 epi...|            6|            78| 50–92 min.|       50|       92|   Renewed|     1|Drama| English|2021-03-16T21:20:...|\n",
            "|          Marco Polo|    Historical drama|    historical,drama|12-Dec-14|2 seasons, 20 epi...|            2|            20| 48–65 min.|       48|       65|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|           Bloodline|            Thriller|            thriller|20-Mar-15|3 seasons, 33 epi...|            3|            33| 48–68 min.|       48|       68|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|              Sense8|     Science fiction|     science-fiction| 5-Jun-15|2 seasons, 24 epi...|            2|            24|45–152 min.|       45|      152|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|              Narcos|         Crime drama|         crime,drama|28-Aug-15|3 seasons, 30 epi...|            3|            30| 43–60 min.|       43|       60|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|     Stranger Things|Science fiction/h...|science-fiction,h...|15-Jul-16|2 seasons, 17 epi...|            2|            17| 42–62 min.|       42|       62|   Renewed|     1|Drama| English|2021-03-16T21:20:...|\n",
            "|        The Get Down|       Musical drama|       musical,drama|12-Aug-16|2 parts, 11 episodes|            0|            11| 50–93 min.|       50|       93|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|           The Crown|    Historical drama|    historical,drama| 4-Nov-16|2 seasons, 20 epi...|            2|            20| 54–61 min.|       54|       61|   Renewed|     1|Drama| English|2021-03-16T21:20:...|\n",
            "|Gilmore Girls: A ...|        Family drama|        family,drama|25-Nov-16|          4 episodes|            0|             4|88–102 min.|       88|      102|Miniseries|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|              The OA|             Mystery|             mystery|16-Dec-16|2 parts, 16 episodes|            0|            16| 31–71 min.|       31|       71|   Pending|     1|Drama| English|2021-03-16T21:20:...|\n",
            "|A Series of Unfor...|Black-comedy mystery|black-comedy,mystery|13-Jan-17|3 seasons, 25 epi...|            3|            25| 36–64 min.|       36|       64|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|      13 Reasons Why|  Teen drama/mystery|  teen,drama,mystery|31-Mar-17|2 seasons, 26 epi...|            2|            26| 49–70 min.|       49|       70|   Renewed|     1|Drama| English|2021-03-16T21:20:...|\n",
            "|               Gypsy|Psychological thr...|psychological,thr...|30-Jun-17|1 season, 10 epis...|            1|            10| 46–58 min.|       46|       58|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|               Ozark|         Crime drama|         crime,drama|21-Jul-17|2 seasons, 20 epi...|            2|            20| 52–80 min.|       52|       80|   Renewed|     1|Drama| English|2021-03-16T21:20:...|\n",
            "|          Mindhunter|         Crime drama|         crime,drama|13-Oct-17|1 season, 10 epis...|            1|            10| 34–60 min.|       34|       60|   Renewed|     1|Drama| English|2021-03-16T21:20:...|\n",
            "|             Godless|             Western|             western|22-Nov-17|          7 episodes|            0|             7| 41–80 min.|       41|       80|Miniseries|     0|Drama| English|2021-03-16T21:20:...|\n",
            "|      Altered Carbon|     Science fiction|     science-fiction| 2-Feb-18|1 season, 10 epis...|            1|            10| 46–66 min.|       46|       66|   Renewed|     1|Drama| English|2021-03-16T21:20:...|\n",
            "|       Seven Seconds|         Crime drama|         crime,drama|23-Feb-18|1 season, 10 epis...|            1|            10| 54–80 min.|       54|       80|     Ended|     0|Drama| English|2021-03-16T21:20:...|\n",
            "+--------------------+--------------------+--------------------+---------+--------------------+-------------+--------------+-----------+---------+---------+----------+------+-----+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Nesta célula são salvos em uma lista todos os campos com suas alterações solicitadas e essa lista será passada em um select mais adiante.\n",
        "\n",
        "Dessa forma além de definir um esquema fixo, o uso de funções como WithColoumn (que podem se tornar bem custosas em termos de processamento) torna-se desnecessário. "
      ],
      "metadata": {
        "id": "-7ml0E_W7sS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#essa função 'Date_format' realiza a alteração do formato '13-Mai-2019' para o formato '2019-05-13' e o tipo date(um dos tipos de datetime)\n",
        "Date_format = udf(lambda linha: parser.parse(linha), DateType())\n",
        "\n",
        "cols = [\n",
        "    col('Title').alias('Título'),\n",
        "    col('Genre').alias('Classificação de Gênero'),\n",
        "    Date_format(col(\"Premiere\")).alias(\"Pré-Estreia\"),\n",
        "    regexp_replace('Seasons', 'TBA', 'a ser anunciado').alias('Temporadas'),\n",
        "    col('SeasonsParsed').alias('Temporadas Disponíveis'),\n",
        "    col('EpisodesParsed').alias('Episódios Disponíveis'),\n",
        "    col('Length').alias('Duração Episódios'),\n",
        "    col('MinLength').alias('Duração Mínima Episódios'),\n",
        "    col('MaxLength').alias('Duração Máxima Episódios'),\n",
        "    col('Status').alias('Situação'),\n",
        "    col('Active').alias('Progressão'),\n",
        "    col('Table').alias('Classificação Principal'),\n",
        "    col('Language').alias('Idioma Oririginal'),\n",
        "    (to_timestamp('dt_inclusao') - timedelta(hours=3)).alias('Data Inclusão'),\n",
        "    (current_timestamp() - timedelta(hours=3)).alias('Data Alteração')\n",
        "]"
      ],
      "metadata": {
        "id": "Flo7IRWXsqXj"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nesta próxima célula eu salvo no mesmo dataframe os campos com todas as alterações solicitadas, através de um select, e já retiro algum possível dado duplicado."
      ],
      "metadata": {
        "id": "4t0kyQhb-BrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Netflix = (\n",
        "    df_Netflix\n",
        "    .select(*cols)\n",
        "    .dropDuplicates(['Título', 'Temporadas', 'Pré-Estreia'])\n",
        ")"
      ],
      "metadata": {
        "id": "wgwcCe_W3V8K"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faço uma contagem de linhas e uma contagem distinta para verificar se há diferença. A ideia é que após o comando de deduplicaçã esses valores sejam iguais."
      ],
      "metadata": {
        "id": "vx5dFnsL_Ea8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Netflix.distinct().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwKju5DG6xiR",
        "outputId": "81b950df-fb75-41cc-8a83-14088a7b407c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "358"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_Netflix.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBb0DSGR6teX",
        "outputId": "941516a5-bfb1-4d0b-c0f7-c411a87294aa"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "358"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nesta próxima célula apenas os campos requisitados para o arquivo .csv são selecionados, junto à ordenação dos dados solicitadas "
      ],
      "metadata": {
        "id": "vkHnKqfT_a7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv = (\n",
        "    df_Netflix\n",
        "    .select(\n",
        "        'Título',\n",
        "        'Classificação de Gênero',\n",
        "        'Temporadas',\n",
        "        'Pré-Estreia',\n",
        "        'Idioma Oririginal',\n",
        "        'Situação',\n",
        "        'Progressão',\n",
        "        'Data Inclusão',\n",
        "        'Data Alteração'\n",
        "    ).orderBy(\n",
        "        col('Progressão').desc(), \n",
        "        col('Classificação de Gênero').desc()\n",
        "        )\n",
        ")\n",
        "\n",
        "\n",
        "df_csv.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R18Tse7iAZga",
        "outputId": "b3e6a255-560c-4643-dc08-3e0b1ac6813a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------------+--------------------+-----------+-----------------+--------+----------+--------------------+--------------------+\n",
            "|              Título|Classificação de Gênero|          Temporadas|Pré-Estreia|Idioma Oririginal|Situação|Progressão|       Data Inclusão|      Data Alteração|\n",
            "+--------------------+-----------------------+--------------------+-----------+-----------------+--------+----------+--------------------+--------------------+\n",
            "|          True Tunes|   chrildrens musica...|     a ser anunciado| 2019-07-12|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|Super Monsters Mo...|   chrildrens musica...|1 season, 4 episodes| 2018-09-14|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|Dance & Sing with...|   chrildrens musica...|1 season, 11 epis...| 2018-05-18|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|        Motown Magic|    childrens-animation|1 season, 25 epis...| 2018-11-20|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "| Mighty Little Bheem|    childrens-animation|1 season, 21 epis...| 2019-04-12|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|   The Dragon Prince|    childrens-animation|2 seasons, 18 epi...| 2018-09-14|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|Charlie's Colorfo...|    childrens-animation|1 season, 13 epis...| 2019-03-22|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|3Below: Tales of ...|    childrens-animation| 1 part, 13 episodes| 2018-12-21|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|               Hilda|    childrens-animation|1 season, 13 epis...| 2018-09-21|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|       Pinky Malinky|    childrens-animation|2 parts, 44 episodes| 2019-01-01|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|         Llama Llama|    childrens-animation|1 season, 15 epis...| 2018-01-26|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|She-Ra and the Pr...|    childrens-animation|2 seasons, 20 epi...| 2018-11-13|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|Harvey Girls Fore...|    childrens-animation|2 seasons, 26 epi...| 2018-06-29|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|  Spirit Riding Free|    childrens-animation|8 seasons, 52 epi...| 2017-05-05|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|Spy Kids: Mission...|    childrens-animation|2 seasons, 20 epi...| 2018-04-20|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|        Larva Island|    childrens-animation|2 seasons, 26 epi...| 2018-10-19|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|Stretch Armstrong...|    childrens-animation|2 seasons, 23 epi...| 2017-11-17|          English| Pending|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|      Super Monsters|    childrens-animation|2 seasons, 16 epi...| 2017-10-13|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|     Carmen Sandiego|    childrens-animation|1 season, 9 episodes| 2019-01-18|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "|   Ask the StoryBots|    childrens-animation|2 seasons, 14 epi...| 2016-08-12|          English| Renewed|         1|2021-03-16 21:20:...|2023-01-04 13:42:...|\n",
            "+--------------------+-----------------------+--------------------+-----------+-----------------+--------+----------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aqui uma nova pasta no Bucket principal é criada para armazenar o csv resultante"
      ],
      "metadata": {
        "id": "03BmWGZwAOCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Bucket_destination = 'detch-bucket01'\n",
        "directory_destination = \"refined_data_Netflix/\" \n",
        "all_obj_bucket = list(s3.Bucket('detch-bucket01').objects.all()) # listando tudo que tem no Bucket principal\n",
        "\n",
        "# para esse tipo de alteração usaremos o CLI do s3 e aqui setamos as credenciais necessárias\n",
        "s3_client = boto3.client('s3',\n",
        "      aws_access_key_id=ACCESS_ID,\n",
        "      aws_secret_access_key= ACCESS_KEY)\n",
        "\n",
        "# só faremos a criação desse novo diretório, caso o mesmo já não exista\n",
        "if s3.ObjectSummary(Bucket_destination, directory_destination) not in all_obj_bucket:\n",
        "  print('Diretório não existente...  criando')\n",
        "  s3_client.put_object(Bucket=Bucket_destination, Key=(directory_destination + '/'))#comando que realiza a criação do novo diretório no s3\n",
        "else:\n",
        "  print('Diretório existente... ')\n",
        "\n",
        "print(\"O diretório de destino no s3 é: \")\n",
        "print(s3.ObjectSummary(Bucket_destination, directory_destination).Bucket().name + '/' + s3.ObjectSummary(Bucket_destination, directory_destination).key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3gBWa4CEoTp",
        "outputId": "6ef9cfd2-b9de-432d-8733-cca0b76c97a0"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diretório existente... \n",
            "O diretório de destino no s3 é: \n",
            "detch-bucket01/refined_data_Netflix/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvaremos e renomearemos o arquivo .csv no sistema local de arquivos, antes de fazer um upload para a pasta de destino do Buacket principal do S3"
      ],
      "metadata": {
        "id": "mLd8d6xZwMpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "folder_destination_sytem = 'refined_data_Netflix'\n",
        "os.path.exists(Bucket_destination +'/' + folder_destination_sytem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA6n2c6loAPc",
        "outputId": "9cface96-bd7e-426b-848a-d0bed437cca7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_destination_sytem = 'refined_data_Netflix'\n",
        "\n",
        "#crio a pasta local onde o .csv será armazenado, caso ela já não exista\n",
        "if not os.path.exists(Bucket_destination +'/' + folder_destination_sytem):\n",
        "  os.mkdir(Bucket_destination +'/' + folder_destination_sytem)\n",
        "\n",
        "# path local onde o .csv será armazenado\n",
        "path_FileCsv_system = Bucket_destination +'/' + folder_destination_sytem +'/' + dt_string + 'Table_Series_Netflix.csv'\n",
        "\n",
        "# File_name = dt_string + 'Table_Series_Netflix.csv'\n",
        "\n",
        "# salvando o .csv na pasta local\n",
        "(\n",
        "    df_csv\n",
        "      .coalesce(1)\n",
        "      .write\n",
        "      .options(delimiter=';', header='true', inferSchema='true')\n",
        "      .mode('overwrite')\n",
        "      .csv(Bucket_destination +'/' + folder_destination_sytem)\n",
        ")\n",
        "\n",
        "# vários outros arquivos são gerados além do csv e para facilitar na hora de renomear e fazer upload, eles serão removidos da pasta local\n",
        "for f in os.listdir(Bucket_destination +'/' + folder_destination_sytem):\n",
        "  if f[-3:] != 'csv':\n",
        "    os.remove(os.path.join(Bucket_destination +'/' + folder_destination_sytem, f))\n",
        "\n",
        "# renomeando o csv que será armazenado no S3\n",
        "csv_file = os.listdir(Bucket_destination +'/' + folder_destination_sytem)[-1]\n",
        "source = Bucket_destination +'/' + folder_destination_sytem +'/' + csv_file\n",
        "dest = path_FileCsv_system\n",
        "os.rename(source, dest)"
      ],
      "metadata": {
        "id": "Zq6XSF02C5CX"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nesta próxima célula, finalmente salvamos o .csv no S3"
      ],
      "metadata": {
        "id": "Zbpjmjvcx7ZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name_source = Bucket_destination +'/' + folder_destination_sytem +'/' + dt_string + 'Table_Series_Netflix.csv' #origem local\n",
        "File_name_dest = 'refined_data_Netflix/' + dt_string + 'Table_Series_Netflix.csv' # destino s3\n",
        "all_obj_bucket = list(s3.Bucket('detch-bucket01').objects.all()) # já havíamos instanciado, mas é necessário atualizar...\n",
        "\n",
        "try:\n",
        "    if s3.ObjectSummary(Bucket_destination, File_name_dest) not in all_obj_bucket:\n",
        "      print('Arquivo não existente...  criando\\n')\n",
        "    else: \n",
        "      print('Arquivo já existe e será sobrescrito\\n')\n",
        "    # fazendo nessa próxima linha o upload\n",
        "    s3_client.upload_file(file_name_source, Bucket_destination, File_name_dest)\n",
        "    # mostrando onde o arquivo foi salvo\n",
        "    path = s3.ObjectSummary(Bucket_destination, directory_destination).Bucket().name + '/' + s3.ObjectSummary(Bucket_destination, File_name_dest).key\n",
        "    print('Upload de arquivo realizado com sucesso\\n')\n",
        "    print('O caminho do mesmo é: {}'.format(path))\n",
        "    print('\\nRemovendo o Arquivo do FileSystem\\n')\n",
        "    os.remove(file_name_source)# excluindo o arquivo do armazenamento local após upload na nuvem\n",
        "except ClientError as e:\n",
        "    logging.error(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDj2BSHjmYwh",
        "outputId": "c300a086-df80-44e4-daf9-2890d9d02189"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo já existe e será sobrescrito\n",
            "\n",
            "Upload de arquivo realizado com sucesso\n",
            "\n",
            "O caminho do mesmo é: detch-bucket01/refined_data_Netflix/20230104Table_Series_Netflix.csv\n",
            "\n",
            "Removendo o Arquivo do FileSystem\n",
            "\n"
          ]
        }
      ]
    }
  ]
}